PEFT（参数高效微调）是一个库，用于高效地将大型预训练模型适配到各种下游应用中，而无需微调模型的所有参数，因为对所有参数进行微调的成本过高。
PEFT方法仅微调少量（额外的）模型参数——这显著降低了计算和存储成本——同时能产生与完全微调模型相当的性能。

## PeftConfig

这是用于存储 [PeftModel] 配置的基础配置类。

## LoraConfig

## get_peft_model

从模型和配置中返回一个 Peft 模型对象，其中模型将被就地修改。
